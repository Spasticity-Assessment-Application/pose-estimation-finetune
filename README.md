# Fine-tuning Pose Estimation

Mod√®le de pose estimation fine-tun√© avec support multi-backbones pour d√©tecter 3 keypoints : hanche, genou, cheville.

**Backbones support√©s** : MobileNetV2 (d√©faut), MobileNetV3, EfficientNetLite0-4, EfficientNetB0-3, EfficientNetV2B0-3

## Installation

### Google Colab

```bash
# Cloner la branche avec l'entra√Ænement avanc√©
!git clone -b tests-upgrade-fine-tunning https://github.com/Spasticity-Assessment-Application/pose-estimation-finetune.git
%cd pose-estimation-finetune

# Installer les d√©pendances
!pip install -q tensorflow==2.15.0 opencv-python pandas tqdm scikit-learn

# Uploader vos donn√©es labeled-data/ puis lancer l'entra√Ænement
!python main.py --save-data
```

### Avec Conda (recommand√©)

```bash
# Cloner/installer l'environnement
./install_conda.sh

# Activer l'environnement
conda activate pose-estimation
```

### Avec pip

```bash
pip install -r requirements.txt
```

## Utilisation

### Pipeline complet (entra√Ænement + export)

```bash
# Avec MobileNetV3Small (recommand√© pour DeepLabCut-style)
python main.py --save-data --backbone MobileNetV3Small

# Avec EfficientNetLite0 (meilleure pr√©cision)
python main.py --save-data --backbone EfficientNetLite0

# Avec EfficientNetV2 (haute pr√©cision)
python main.py --save-data --backbone EfficientNetV2B0
```

### Utiliser un mod√®le d√©j√† entra√Æn√©

```bash
# Charger depuis un mod√®le sp√©cifique
python main.py --skip-data-prep --skip-training --model-path output/models/pose_model_YYYYMMDD_HHMMSS_saved_model
```

## Test du mod√®le

### Sur une vid√©o (TFLite - recommand√© pour production)

```bash
python test_video.py --video "votre_video.mp4"
# Sortie: votre_video_dynamic_annotated.mp4
```

### Sur une vid√©o (TFLite haute pr√©cision - pour validation)

```bash
python test_video.py --video "votre_video.mp4" --model "output/models/pose_model_float32.tflite"
# Sortie: votre_video_float32_annotated.mp4
```

### Sur une vid√©o (Keras - pour validation)

```bash
python test_video_keras.py --video "votre_video.mp4"
# Sortie: votre_video_keras_annotated.mp4
```

### Sur une vid√©o (Keras - pour validation)

```bash
python test_video_keras.py --video "votre_video.mp4"
```

### Comparer pr√©cision Keras vs TFLite

```bash
python quick_compare.py
# Compare Keras vs TFLite Dynamic (mod√®le recommand√©)
# G√©n√®re: *_keras_annotated.mp4 et *_dynamic_annotated.mp4
```

### Export analyse vid√©o en CSV (comparaison mod√®les)

```bash
# Exporte les positions des keypoints pour tous les formats de mod√®les
python export_video_analysis.py --video "votre_video.mp4" --model-dir "output/MNv2_20251113_123456"

# Sortie:
#   - votre_video_analysis.csv (format long)
#   - votre_video_analysis_pivot.csv (format pivot pour comparaison)
# Compare: Keras, TFLite float32, dynamic, int8
```

### √âvaluation sur donn√©es de test annot√©es

```bash
# √âvaluer le mod√®le sur des donn√©es de test annot√©es
python evaluate_test_labeled_data.py \
    --model-dir output/DLC_MNv3S_20251120_195929 \
    --test-data-dir test-labeled-data
```

## √âvaluation du Mod√®le

Ce script permet d'√©valuer un mod√®le de pose estimation sur des donn√©es de test annot√©es dans le dossier `test-labeled-data`.

### Structure des Donn√©es de Test

Le dossier `test-labeled-data` doit contenir des sous-dossiers, chacun repr√©sentant une vid√©o annot√©e :

```
test-labeled-data/
‚îú‚îÄ‚îÄ video1_folder/
‚îÇ   ‚îú‚îÄ‚îÄ CollectedData_scoring.csv  # Annotations CSV
‚îÇ   ‚îú‚îÄ‚îÄ CollectedData_scoring.h5   # Annotations HDF5 (optionnel)
‚îÇ   ‚îú‚îÄ‚îÄ img001.png                 # Images annot√©es
‚îÇ   ‚îú‚îÄ‚îÄ img002.png
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ video2_folder/
    ‚îî‚îÄ‚îÄ ...
```

### Format du CSV d'Annotations

Le fichier CSV doit suivre le format DeepLabCut :

```csv
scorer,,,bodypart1,bodypart1,bodypart2,bodypart2,...
bodyparts,,,x,y,x,y,...
labeled-data,folder_name,image_name,x1,y1,x2,y2,...
```

### M√©triques Calcul√©es

- **PCK (Percentage of Correct Keypoints)** : Pourcentage de keypoints correctement localis√©s (seuil 5% de la taille d'image)
- **MSE** : Erreur quadratique moyenne en unit√©s normalis√©es (0-1)
- **Confiance** : Confiance moyenne des pr√©dictions du mod√®le

### Exemple de Sortie

```
üìÅ √âvaluation du dossier: video1_folder
üìä 20 images annot√©es trouv√©es
√âvaluation video1_folder: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:02<00:00,  8.49it/s]
   - PCK: 0.567 ¬± 0.238
   - MSE: 0.0403 ¬± 0.0293 (normalis√©)
   - Confiance moyenne: 0.44 ¬± 0.18

================================================================================
üìä R√âSULTATS GLOBAUX
================================================================================
üìà Nombre total d'images √©valu√©es: 20
üéØ PCK moyen global: 0.567
üìè MSE moyen global: 0.0403 (normalis√©)
üîç Confiance moyenne globale: 0.44
```

### Pr√©diction sur une image

```bash
python predict.py --image "votre_image.jpg" --model "output/models/pose_model_best.h5"
```

## Options principales

### main.py

- `--backbone` : Choix du backbone (MobileNetV2, EfficientNetLite0-4, etc. - d√©faut: MobileNetV2)
- `--skip-data-prep` : Utiliser les donn√©es pr√©trait√©es
- `--skip-training` : Charger un mod√®le existant
- `--skip-export` : Ne pas exporter en TFLite
- `--save-data` : Sauvegarder les donn√©es pr√©trait√©es
- `--model-path` : Chemin vers un mod√®le existant

### test_video.py / test_video_keras.py

- `--video` : Chemin vers la vid√©o √† analyser
- `--model` : Chemin vers le mod√®le (optionnel)

## Donn√©es d'entra√Ænement

Les donn√©es doivent √™tre organis√©es comme suit :

```
labeled-data/
‚îú‚îÄ‚îÄ 101D/
‚îÇ   ‚îú‚îÄ‚îÄ CollectedData_*.csv    # Fichier CSV DeepLabCut (nom variable)
‚îÇ   ‚îî‚îÄ‚îÄ [images .png]
‚îú‚îÄ‚îÄ 101D_labeled/              # Dossier ignor√© automatiquement
‚îî‚îÄ‚îÄ ...
```

Format CSV DeepLabCut avec colonnes :

- Colonne 2 : nom de l'image
- Colonnes 3-4 : hanche (x,y)
- Colonnes 5-6 : genou (x,y)
- Colonnes 7-8 : cheville (x,y)

## R√©sultats

Apr√®s ex√©cution, les fichiers sont sauvegard√©s dans `output/` avec une structure organis√©e :

```
output/
‚îî‚îÄ‚îÄ Backbone_Date/                    # ex: MNv2_20251108_190128/
    ‚îú‚îÄ‚îÄ models/                       # Mod√®les entra√Æn√©s
    ‚îÇ   ‚îú‚îÄ‚îÄ pose_model_best.h5        # Meilleur mod√®le Keras
    ‚îÇ   ‚îú‚îÄ‚îÄ pose_model_final.h5       # Mod√®le final Keras
    ‚îÇ   ‚îú‚îÄ‚îÄ pose_model_saved_model/   # SavedModel pour TFLite
    ‚îÇ   ‚îú‚îÄ‚îÄ pose_model_dynamic.tflite
    ‚îÇ   ‚îî‚îÄ‚îÄ pose_model_float32.tflite
    ‚îú‚îÄ‚îÄ logs/                         # Logs et m√©triques
    ‚îÇ   ‚îú‚îÄ‚îÄ pose_model_YYYYMMDD-HHMMSS/  # TensorBoard
    ‚îÇ   ‚îú‚îÄ‚îÄ pose_model_history.png    # Courbes d'apprentissage
    ‚îÇ   ‚îî‚îÄ‚îÄ pose_model_training_log.csv # Logs CSV
    ‚îú‚îÄ‚îÄ videos/                       # Vid√©os annot√©es de test
    ‚îî‚îÄ‚îÄ preprocessed_data.npz         # Donn√©es pr√©trait√©es
```

### Mod√®les export√©s

- **Dynamic (.tflite)** ‚≠ê RECOMMAND√â : 6MB, pr√©cision ~1px, production mobile
- **Float32 (.tflite)** üî¨ TESTS : 22MB, pr√©cision maximale, validation

## M√©triques

Le mod√®le atteint g√©n√©ralement (r√©sultats du dernier test) :

- **Pr√©cision finale** : MAE = 0.119 (pixels)
- **Taille mod√®le Dynamic** : ~6MB (optimis√© pour mobile)
- **Taille mod√®le Float32** : ~22MB (haute pr√©cision)
- **Vitesse** : ~30 FPS sur CPU mobile
- **Convergence** : Loss de 0.163 ‚Üí 0.015 en 5 epochs

## Architecture

- **Backbone** : Multi-backbone support (MobileNetV2 par d√©faut, EfficientNetLite, EfficientNetB, EfficientNetV2)
- **T√™te** : D√©convolution 3 √©tages avec adaptation automatique √† la sortie du backbone
- **Sortie** : Heatmaps 48x48x3
- **Fine-tuning** : Backbone gel√©, seulement la t√™te entra√Æn√©e
- **Augmentation** : Rotation, translation, zoom, flip horizontal

### Backbones disponibles

**L√©gers (mobile/edge) :**

- `MobileNetV2` (‚≠ê d√©faut) : 192x192, ~3.5M params, tr√®s rapide
- `MobileNetV3Small` : 192x192, ~2.5M params, ultra-l√©ger
- `EfficientNetLite0-4` : 224-300px, pr√©cision progressive

**Haute pr√©cision :**

- `EfficientNetB0-3` : 224-300px, meilleure pr√©cision
- `EfficientNetV2B0-3` : 224-300px, entra√Ænement plus rapide
