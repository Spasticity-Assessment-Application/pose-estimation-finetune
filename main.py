"""
Script principal pour le pipeline DeepLabCut-Style
Usage: python main.py --backbone MobileNetV3Small --save-data
"""
import os
import argparse
import numpy as np
from datetime import datetime
import config
from data_preprocessing import prepare_data
from model_deeplabcut import create_deeplabcut_model
from train_deeplabcut import train_deeplabcut_progressive
from train_deeplabcut import save_final_model, plot_training_history
from export_tflite import export_model, test_tflite_model


def main(args):
    """Pipeline complet DeepLabCut-Style"""
    print("\n" + "=" * 80)
    print("üî¨ PIPELINE DEEPLABCUT-STYLE - POSE ESTIMATION")
    print("=" * 80)

    # Configurer le backbone (utilise la valeur par d√©faut de config.BACKBONE)
    config.BACKBONE = args.backbone
    
    # Utiliser toujours les tailles DeepLabCut
    if args.backbone in config.DEEPLABCUT_INPUT_SIZES:
        recommended_size = config.DEEPLABCUT_INPUT_SIZES[args.backbone]
        config.IMAGE_SIZE = recommended_size
        config.INPUT_SHAPE = (*recommended_size, 3)
        
        # Calculer heatmap size avec le stride
        heatmap_h = recommended_size[0] // config.DEEPLABCUT_HEATMAP_STRIDE
        heatmap_w = recommended_size[1] // config.DEEPLABCUT_HEATMAP_STRIDE
        config.HEATMAP_SIZE = (heatmap_h, heatmap_w)
        
        print(f"\nüì¶ Backbone: {args.backbone}")
        print(f"üìä Input size: {recommended_size[0]}√ó{recommended_size[1]}")
        print(f"üìä Heatmap size: {heatmap_h}√ó{heatmap_w} (stride {config.DEEPLABCUT_HEATMAP_STRIDE})")
    else:
        # Fallback pour backbones non DeepLabCut
        print(f"\n‚ö†Ô∏è  Backbone {args.backbone} non support√© en mode DeepLabCut, utilisation des param√®tres par d√©faut")
        print(f"üì¶ Backbone: {args.backbone}")
        print(f"üìä Input size: {config.IMAGE_SIZE[0]}√ó{config.IMAGE_SIZE[1]}")
        print(f"üìä Heatmap size: {config.HEATMAP_SIZE[0]}√ó{config.HEATMAP_SIZE[1]}")

    # √âTAPE 0: Configuration des dossiers
    print("\nüìÅ CONFIGURATION DES DOSSIERS")
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    model_folder_name = config.get_model_folder_name(config.BACKBONE, timestamp)
    model_dir, models_dir, logs_dir, videos_dir = config.setup_model_directories(model_folder_name)

    print(f"üìÇ Dossier mod√®le: {model_folder_name}")
    print(f"   - Mod√®les: {models_dir}")
    print(f"   - Logs: {logs_dir}")
    print(f"   - Vid√©os: {videos_dir}")

    tflite_path = None  # Initialiser

    # √âTAPE 1: Pr√©paration des donn√©es
    if not args.skip_data_prep:
        print("\n√âTAPE 1/4 - PR√âPARATION DES DONN√âES")
        X_train, X_val, y_train, y_val = prepare_data()

        if args.save_data:
            data_path = os.path.join(model_dir, "preprocessed_data.npz")
            np.savez_compressed(data_path, X_train=X_train, X_val=X_val, y_train=y_train, y_val=y_val)
            print(f"üíæ Donn√©es sauvegard√©es: {data_path}")
    else:
        print("\n‚è© Chargement des donn√©es pr√©trait√©es...")
        data_path = os.path.join(model_dir, "preprocessed_data.npz")
        data = np.load(data_path)
        X_train = data['X_train']
        X_val = data['X_val']
        y_train = data['y_train']
        y_val = data['y_val']
        print(f"‚úÖ Donn√©es charg√©es depuis: {data_path}")
    
    # √âTAPE 2: Construction du mod√®le
    if not args.skip_training:
        print("\n√âTAPE 2/4 - CONSTRUCTION DU MOD√àLE")
        model = create_deeplabcut_model()

        # √âTAPE 3: Entra√Ænement
        print("\n√âTAPE 3/4 - ENTRA√éNEMENT DEEPLABCUT-STYLE")
        model_name = "pose_model_dlc"  # Nom pour DeepLabCut

        history, metrics = train_deeplabcut_progressive(
            model=model,
            X_train=X_train,
            y_train=y_train,
            X_val=X_val,
            y_val=y_val,
            model_name=model_name,
            model_dir=model_dir
        )
        
        final_model_path, saved_model_dir = save_final_model(model, model_name, model_dir)

        if args.plot_history:
            plot_path = os.path.join(logs_dir, f"{model_name}_history.png")
            plot_training_history(history, save_path=plot_path)
    else:
        print("\n‚è© Chargement du mod√®le entra√Æn√©...")
        model_path = args.model_path
        if not model_path:
            raise ValueError("Vous devez fournir --model_path si --skip_training est activ√©")
        saved_model_dir = model_path
        model_name = "pose_model"
        print(f"‚úÖ Mod√®le charg√© depuis: {saved_model_dir}")

    # √âTAPE 4: Export TFLite
    tflite_paths = None
    if not args.skip_export:
        print("\n√âTAPE 4/4 - EXPORT TENSORFLOW LITE")
        tflite_paths = export_model(model_path=saved_model_dir, X_val=X_val, model_name=model_name, model_dir=model_dir)

        if args.test_tflite:
            # Tester le mod√®le recommand√© (dynamic)
            test_tflite_model(tflite_paths['dynamic'], X_val, y_val, num_samples=10)
    
    # R√©sum√© final
    print("\n" + "=" * 80)
    print("üéâ PIPELINE DEEPLABCUT TERMIN√â AVEC SUCC√àS!")
    print("=" * 80)
    print(f"\nüìÇ R√©sultats sauvegard√©s dans: {model_dir}")
    print(f"   - Mod√®les: {models_dir}")
    print(f"   - Logs: {logs_dir}")
    print(f"   - Vid√©os: {videos_dir}")

    print("\n" + "=" * 80)


def parse_arguments():
    """
    Parse les arguments de la ligne de commande
    """
    parser = argparse.ArgumentParser(
        description="Pipeline DeepLabCut-Style pour la pose estimation"
    )
    
    # Options de workflow
    parser.add_argument(
        '--skip-data-prep',
        action='store_true',
        help="Sauter la pr√©paration des donn√©es (charge depuis le cache)"
    )
    parser.add_argument(
        '--skip-training',
        action='store_true',
        help="Sauter l'entra√Ænement (utilise un mod√®le existant)"
    )
    parser.add_argument(
        '--skip-export',
        action='store_true',
        help="Sauter l'export TFLite"
    )
    
    # Configuration du mod√®le
    parser.add_argument(
        '--backbone',
        type=str,
        default=config.BACKBONE,
        choices=[
            'MobileNetV2', 'MobileNetV3Small', 'MobileNetV3Large',
            'EfficientNetLite0', 'EfficientNetLite1', 'EfficientNetLite2', 
            'EfficientNetLite3', 'EfficientNetLite4'
        ],
        help="Backbone √† utiliser (d√©faut: MobileNetV3Small pour DeepLabCut)"
    )
    
    # Options de sauvegarde
    parser.add_argument(
        '--save-data',
        action='store_true',
        help="Sauvegarder les donn√©es pr√©trait√©es"
    )
    parser.add_argument(
        '--plot-history',
        action='store_true',
        default=True,
        help="Tracer les courbes d'apprentissage"
    )
    parser.add_argument(
        '--test-tflite',
        action='store_true',
        default=True,
        help="Tester le mod√®le TFLite apr√®s conversion"
    )
    
    # Chemins
    parser.add_argument(
        '--model-path',
        type=str,
        default=None,
        help="Chemin vers un mod√®le existant (si --skip-training)"
    )
    
    return parser.parse_args()


if __name__ == "__main__":
    # Parser les arguments
    args = parse_arguments()
    
    # Lancer le pipeline
    try:
        main(args)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Pipeline interrompu par l'utilisateur")
    except Exception as e:
        print(f"\n\n‚ùå Erreur lors de l'ex√©cution du pipeline:")
        print(f"   {type(e).__name__}: {e}")
        raise
