"""
Construction du mod√®le de pose estimation avec support multi-backbones
Supporte: MobileNetV2/V3, EfficientNetLite, EfficientNetB, EfficientNetV2
"""
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model
from tensorflow.keras.applications import (
    MobileNetV2, MobileNetV3Small, MobileNetV3Large,
    EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3,
    EfficientNetV2B0, EfficientNetV2B1, EfficientNetV2B2, EfficientNetV2B3
)
import config


def get_backbone(backbone_name="MobileNetV2", input_shape=(192, 192, 3), alpha=1.0):
    """
    Charge le backbone pr√©-entra√Æn√©
    
    Args:
        backbone_name: Nom du backbone (MobileNetV2, MobileNetV3Small/Large, 
                       EfficientNetLite0-4, EfficientNetB0-3, EfficientNetV2B0-3)
        input_shape: Forme de l'entr√©e (H, W, C)
        alpha: Width multiplier (seulement pour MobileNet)
    
    Returns:
        backbone: Mod√®le Keras du backbone
    """
    # MobileNet backbones
    if backbone_name == "MobileNetV2":
        backbone = MobileNetV2(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS,
            alpha=alpha
        )
    elif backbone_name == "MobileNetV3Small":
        backbone = MobileNetV3Small(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS,
            alpha=alpha,
            minimalistic=False
        )
    elif backbone_name == "MobileNetV3Large":
        backbone = MobileNetV3Large(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS,
            alpha=alpha,
            minimalistic=False
        )
    
    # EfficientNetLite backbones (l√©gers, optimis√©s edge/mobile)
    elif backbone_name == "EfficientNetLite0":
        backbone = EfficientNetB0(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetLite1":
        backbone = EfficientNetB1(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetLite2":
        backbone = EfficientNetB2(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetLite3":
        backbone = EfficientNetB3(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetLite4":
        # Lite4 utilise B3 comme base avec optimisations
        backbone = EfficientNetB3(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    
    # EfficientNetB backbones (haute pr√©cision)
    elif backbone_name == "EfficientNetB0":
        backbone = EfficientNetB0(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetB1":
        backbone = EfficientNetB1(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetB2":
        backbone = EfficientNetB2(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetB3":
        backbone = EfficientNetB3(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    
    # EfficientNetV2 backbones (plus rapides, meilleure pr√©cision)
    elif backbone_name == "EfficientNetV2B0":
        backbone = EfficientNetV2B0(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetV2B1":
        backbone = EfficientNetV2B1(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetV2B2":
        backbone = EfficientNetV2B2(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    elif backbone_name == "EfficientNetV2B3":
        backbone = EfficientNetV2B3(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS
        )
    
    else:
        raise ValueError(f"Backbone non support√©: {backbone_name}. "
                        f"Backbones disponibles: MobileNetV2, MobileNetV3Small/Large, "
                        f"EfficientNetLite0-4, EfficientNetB0-3, EfficientNetV2B0-3")
    
    return backbone


def build_pose_model(num_keypoints=3, backbone_name="MobileNetV2", input_shape=(192, 192, 3)):
    """
    Construit le mod√®le complet de pose estimation
    
    Architecture:
        - Backbone (MobileNet/EfficientNet pr√©-entra√Æn√© sur ImageNet)
        - Upsampling progressif adaptatif
        - T√™te convolutionnelle pour pr√©dire les heatmaps
    
    Args:
        num_keypoints: Nombre de points cl√©s √† pr√©dire
        backbone_name: Nom du backbone
        input_shape: Forme de l'entr√©e (H, W, C)
    
    Returns:
        model: Mod√®le Keras compil√©
    """
    # 1. Cr√©er l'entr√©e
    inputs = keras.Input(shape=input_shape, name="image_input")
    
    # 2. Charger le backbone
    backbone = get_backbone(backbone_name, input_shape, config.ALPHA)
    
    # GELER LE BACKBONE (fine-tuning uniquement de la t√™te)
    backbone.trainable = False
    print(f"üîí Backbone gel√© - {sum([1 for l in backbone.layers if not l.trainable])} couches non-entra√Ænables")
    
    # 3. Extraire les features du backbone
    x = backbone(inputs)
    
    # 4. D√©terminer la forme de sortie du backbone pour adapter la t√™te
    # La plupart des backbones r√©duisent par un facteur de 32
    # Ex: 192/32=6x6, 224/32=7x7, 240/32=7.5‚âà8x8
    reduction_ratio = config.BACKBONE_REDUCTION_RATIOS.get(backbone_name, 32)
    backbone_output_size = input_shape[0] // reduction_ratio
    
    print(f"üìê Sortie backbone: ~{backbone_output_size}x{backbone_output_size}")
    print(f"üéØ Cible heatmaps: {config.HEATMAP_SIZE[0]}x{config.HEATMAP_SIZE[1]}")
    
    # 5. Calculer le nombre d'upsampling n√©cessaires
    # Pour passer de backbone_output_size √† HEATMAP_SIZE (48x48)
    # On fait 3 upsampling x2 : 6‚Üí12‚Üí24‚Üí48 ou 7‚Üí14‚Üí28‚Üí56 (puis on ajuste)
    
    # Premi√®re upsampling: x2
    x = layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', name='upsample_1')(x)
    x = layers.BatchNormalization(name='bn_1')(x)
    x = layers.ReLU(name='relu_1')(x)
    
    # Deuxi√®me upsampling: x2
    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', name='upsample_2')(x)
    x = layers.BatchNormalization(name='bn_2')(x)
    x = layers.ReLU(name='relu_2')(x)
    
    # Troisi√®me upsampling: x2
    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', name='upsample_3')(x)
    x = layers.BatchNormalization(name='bn_3')(x)
    x = layers.ReLU(name='relu_3')(x)
    
    # 6. Ajuster √† la taille exacte des heatmaps si n√©cessaire
    # Utiliser Resizing pour garantir la taille exacte
    current_size = backbone_output_size * 8  # Apr√®s 3 upsampling x2
    if current_size != config.HEATMAP_SIZE[0]:
        x = layers.Resizing(
            config.HEATMAP_SIZE[0], 
            config.HEATMAP_SIZE[1], 
            interpolation='bilinear',
            name='resize_to_heatmap_size'
        )(x)
        print(f"üîß Redimensionnement: {current_size}x{current_size} ‚Üí {config.HEATMAP_SIZE[0]}x{config.HEATMAP_SIZE[1]}")
    
    # 7. Couche finale pour pr√©dire les heatmaps
    # Conv2D avec activation sigmoid pour avoir des valeurs entre 0 et 1
    outputs = layers.Conv2D(num_keypoints, (1, 1), padding='same', activation='sigmoid', name='heatmaps')(x)
    
    # 8. Cr√©er le mod√®le
    model = Model(inputs=inputs, outputs=outputs, name=f'pose_estimation_{backbone_name}')
    
    return model


def compile_model(model, learning_rate=1e-4, optimizer_name='adam'):
    """
    Compile le mod√®le avec la loss et l'optimiseur
    
    Args:
        model: Mod√®le Keras
        learning_rate: Taux d'apprentissage
        optimizer_name: Nom de l'optimiseur
    
    Returns:
        model: Mod√®le compil√©
    """
    # Choisir l'optimiseur
    if optimizer_name.lower() == 'adam':
        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    elif optimizer_name.lower() == 'sgd':
        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)
    else:
        raise ValueError(f"Optimiseur non support√©: {optimizer_name}")
    
    # Compiler avec MSE loss
    model.compile(
        optimizer=optimizer,
        loss='mse',  # Mean Squared Error entre heatmaps pr√©dites et vraies
        metrics=['mae']  # Mean Absolute Error comme m√©trique additionnelle
    )
    
    return model


def create_model():
    """
    Pipeline complet de cr√©ation et compilation du mod√®le
    
    Returns:
        model: Mod√®le Keras compil√© et pr√™t √† l'entra√Ænement
    """
    print("=" * 60)
    print("üèóÔ∏è  CONSTRUCTION DU MOD√àLE")
    print("=" * 60)
    
    # 1. Construire le mod√®le
    print(f"\nüìê Construction du mod√®le avec backbone: {config.BACKBONE}")
    model = build_pose_model(
        num_keypoints=config.NUM_KEYPOINTS,
        backbone_name=config.BACKBONE,
        input_shape=config.INPUT_SHAPE
    )
    
    # 2. Compiler le mod√®le
    print(f"‚öôÔ∏è  Compilation avec {config.OPTIMIZER}, lr={config.LEARNING_RATE}")
    model = compile_model(
        model,
        learning_rate=config.LEARNING_RATE,
        optimizer_name=config.OPTIMIZER
    )
    
    # 3. Afficher le r√©sum√©
    print(f"\nüìä R√©sum√© du mod√®le:")
    model.summary()
    
    print("\n‚úÖ Mod√®le cr√©√© et compil√© avec succ√®s!")
    print("=" * 60)
    
    return model


if __name__ == "__main__":
    # Test de la construction du mod√®le
    model = create_model()
    
    print("\nüìä Informations du mod√®le:")
    print(f"   - Input shape: {model.input_shape}")
    print(f"   - Output shape: {model.output_shape}")
    print(f"   - Nombre de param√®tres: {model.count_params():,}")
