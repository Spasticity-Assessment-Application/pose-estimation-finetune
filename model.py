"""
Construction du mod√®le de pose estimation bas√© sur MobileNetV2
"""
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Model
from tensorflow.keras.applications import MobileNetV2, MobileNetV3Small, MobileNetV3Large
import config


def get_backbone(backbone_name="MobileNetV2", input_shape=(192, 192, 3), alpha=1.0):
    """
    Charge le backbone pr√©-entra√Æn√©
    
    Args:
        backbone_name: Nom du backbone ("MobileNetV2", "MobileNetV3Small", "MobileNetV3Large")
        input_shape: Forme de l'entr√©e (H, W, C)
        alpha: Width multiplier
    
    Returns:
        backbone: Mod√®le Keras du backbone
    """
    if backbone_name == "MobileNetV2":
        backbone = MobileNetV2(
            input_shape=input_shape,
            include_top=False,  # On retire la t√™te de classification
            weights=config.PRETRAINED_WEIGHTS,
            alpha=alpha
        )
    elif backbone_name == "MobileNetV3Small":
        backbone = MobileNetV3Small(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS,
            alpha=alpha,
            minimalistic=False
        )
    elif backbone_name == "MobileNetV3Large":
        backbone = MobileNetV3Large(
            input_shape=input_shape,
            include_top=False,
            weights=config.PRETRAINED_WEIGHTS,
            alpha=alpha,
            minimalistic=False
        )
    else:
        raise ValueError(f"Backbone non support√©: {backbone_name}")
    
    return backbone


def build_pose_model(num_keypoints=3, backbone_name="MobileNetV2", input_shape=(192, 192, 3)):
    """
    Construit le mod√®le complet de pose estimation
    
    Architecture:
        - Backbone MobileNet (pr√©-entra√Æn√© sur ImageNet)
        - Upsampling progressif
        - T√™te convolutionnelle pour pr√©dire les heatmaps
    
    Args:
        num_keypoints: Nombre de points cl√©s √† pr√©dire
        backbone_name: Nom du backbone
        input_shape: Forme de l'entr√©e (H, W, C)
    
    Returns:
        model: Mod√®le Keras compil√©
    """
    # 1. Cr√©er l'entr√©e
    inputs = keras.Input(shape=input_shape, name="image_input")
    
    # 2. Charger le backbone
    backbone = get_backbone(backbone_name, input_shape, config.ALPHA)
    
    # GELER LE BACKBONE (fine-tuning uniquement de la t√™te)
    backbone.trainable = False
    print(f"üîí Backbone gel√© - {sum([1 for l in backbone.layers if not l.trainable])} couches non-entra√Ænables")
    
    # 3. Extraire les features du backbone
    x = backbone(inputs)
    
    # √Ä ce stade, x a une forme approximative de (batch, 6, 6, 1280) pour MobileNetV2
    # On veut arriver √† (batch, 48, 48, num_keypoints)
    
    # 4. T√™te de d√©convolution pour upsampler vers la taille des heatmaps
    
    # Premi√®re upsampling: 6x6 -> 12x12
    x = layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', name='upsample_1')(x)
    x = layers.BatchNormalization(name='bn_1')(x)
    x = layers.ReLU(name='relu_1')(x)
    
    # Deuxi√®me upsampling: 12x12 -> 24x24
    x = layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', name='upsample_2')(x)
    x = layers.BatchNormalization(name='bn_2')(x)
    x = layers.ReLU(name='relu_2')(x)
    
    # Troisi√®me upsampling: 24x24 -> 48x48
    x = layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', name='upsample_3')(x)
    x = layers.BatchNormalization(name='bn_3')(x)
    x = layers.ReLU(name='relu_3')(x)
    
    # 5. Couche finale pour pr√©dire les heatmaps
    # On utilise une Conv2D avec activation sigmoid pour avoir des valeurs entre 0 et 1
    outputs = layers.Conv2D(num_keypoints, (1, 1), padding='same', activation='sigmoid', name='heatmaps')(x)
    
    # 6. Cr√©er le mod√®le
    model = Model(inputs=inputs, outputs=outputs, name='pose_estimation_model')
    
    return model


def compile_model(model, learning_rate=1e-4, optimizer_name='adam'):
    """
    Compile le mod√®le avec la loss et l'optimiseur
    
    Args:
        model: Mod√®le Keras
        learning_rate: Taux d'apprentissage
        optimizer_name: Nom de l'optimiseur
    
    Returns:
        model: Mod√®le compil√©
    """
    # Choisir l'optimiseur
    if optimizer_name.lower() == 'adam':
        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)
    elif optimizer_name.lower() == 'sgd':
        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)
    else:
        raise ValueError(f"Optimiseur non support√©: {optimizer_name}")
    
    # Compiler avec MSE loss
    model.compile(
        optimizer=optimizer,
        loss='mse',  # Mean Squared Error entre heatmaps pr√©dites et vraies
        metrics=['mae']  # Mean Absolute Error comme m√©trique additionnelle
    )
    
    return model


def create_model():
    """
    Pipeline complet de cr√©ation et compilation du mod√®le
    
    Returns:
        model: Mod√®le Keras compil√© et pr√™t √† l'entra√Ænement
    """
    print("=" * 60)
    print("üèóÔ∏è  CONSTRUCTION DU MOD√àLE")
    print("=" * 60)
    
    # 1. Construire le mod√®le
    print(f"\nüìê Construction du mod√®le avec backbone: {config.BACKBONE}")
    model = build_pose_model(
        num_keypoints=config.NUM_KEYPOINTS,
        backbone_name=config.BACKBONE,
        input_shape=config.INPUT_SHAPE
    )
    
    # 2. Compiler le mod√®le
    print(f"‚öôÔ∏è  Compilation avec {config.OPTIMIZER}, lr={config.LEARNING_RATE}")
    model = compile_model(
        model,
        learning_rate=config.LEARNING_RATE,
        optimizer_name=config.OPTIMIZER
    )
    
    # 3. Afficher le r√©sum√©
    print(f"\nüìä R√©sum√© du mod√®le:")
    model.summary()
    
    print("\n‚úÖ Mod√®le cr√©√© et compil√© avec succ√®s!")
    print("=" * 60)
    
    return model


if __name__ == "__main__":
    # Test de la construction du mod√®le
    model = create_model()
    
    print("\nüìä Informations du mod√®le:")
    print(f"   - Input shape: {model.input_shape}")
    print(f"   - Output shape: {model.output_shape}")
    print(f"   - Nombre de param√®tres: {model.count_params():,}")
